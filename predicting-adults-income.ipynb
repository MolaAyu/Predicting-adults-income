{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Working with a dataset with categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this step we start by reading the csv file using panda library \n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file.\n",
    "data_training = pd.read_csv(\"adult_training.CSV\")\n",
    "data_test = pd.read_csv(\"adult_test_data.CSV\")\n",
    "\n",
    "Xtrain = data_training.drop('target', axis=1)\n",
    "Ytrain = data_training['target']\n",
    "\n",
    "Xtest = data_test.drop('target',axis=1)\n",
    "Ytest = data_test['target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 objective is to read the data from the training and testing files. Unlike the previous assignemnt here we didnt split the data to training and testing because its already splitted in two files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Encoding the features as numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_for_my_training_data = Xtrain.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_for_my_test_data = Xtest.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Ytrain)\n",
    "Ytrain=le.transform(Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In manner to transform the data to numerical data we need to create dictionary vectors for the training and the test data. By using Pandas which includes a utility to convert a DataFrame into a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32561x108 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 394963 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train_encoded = dv.fit_transform(dicts_for_my_training_data)\n",
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step was to create the DictVectorizer and then fit the lables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Ytrain)\n",
    "Ytrain=le.transform(Ytrain)\n",
    "Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817726807771718"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf1 = DecisionTreeClassifier()\n",
    "cross_val_score(clf1, X_train_encoded, Ytrain).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we have used the DecisionTreeClassifier and used the accuracy measure cross validation score to test the accuracy \n",
    "of the data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16281x108 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 227934 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_encoded = dv.transform(dicts_for_my_test_data)\n",
    "X_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Ytest)\n",
    "Ytest=le.transform(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fitted the test data befoer using the pipline to combine all the previous steps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Combining the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('dictvectorizer', DictVectorizer()),\n",
       "                ('decisiontreeclassifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pipeline = make_pipeline(DictVectorizer(),DecisionTreeClassifier())\n",
    "pipeline.fit(dicts_for_my_training_data, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict on new data it is as simple as calling the predict method and the preprocessing steps will be applied followed by the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new = pipeline.predict(dicts_for_my_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8219400059897449"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation performance of test set with the predicted label\n",
    "cross_val_score(clf1, X_test_encoded, Y_new).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8094099346785868"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation performance of test data usinf decision tree classifier\n",
    "cross_val_score(clf1, X_test_encoded, Ytest).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Decision trees and random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Underfitting and overfitting in decision tree classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Ytrain)\n",
    "Ytrain=le.transform(Ytrain)\n",
    "Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Ytest)\n",
    "Ytest=le.transform(Ytest)\n",
    "Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf2= DecisionTreeClassifier()\n",
    "clf2.fit(X_train_encoded, Ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n",
      "[0 0 1 ... 1 0 0]\n",
      "Accuracy of training data: 0.9999692884125181\n",
      "Accuracy of test data: 0.8114980652294085\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "dot_data=StringIO()\n",
    "tree.export_graphviz(clf2,out_file=dot_data,filled=True,rounded=False,impurity=False)\n",
    "graph=pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png)\n",
    "\n",
    "predict1=clf2.predict(X_train_encoded)\n",
    "print(predict1)\n",
    "predict2=clf2.predict(X_test_encoded)\n",
    "print(predict2)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "c1=confusion_matrix(Ytrain,predict1)\n",
    "c1\n",
    "\n",
    "total=sum(sum(c1))\n",
    "#accuracy=(c1[0,0]+c1[1,1])/total\n",
    "a1=c1[0,0]\n",
    "a2=c1[1,1]\n",
    "accuracy=(a1+a2)/total\n",
    "print('Accuracy of training data:',accuracy)\n",
    "\n",
    "c2=confusion_matrix(Ytest,predict2)\n",
    "c2\n",
    "total1=sum(sum(c2))\n",
    "a3=c2[0,0]\n",
    "a4=c2[1,1]\n",
    "accuracy1=(a3+a4)/total1\n",
    "print('Accuracy of test data:',accuracy1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of trianing set is almost 100%. and using the same model the test data accuracy is 81%. The model is good in trainning data and it is also good in test data.No problem with overfitting. Since we have nice predition on the future data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3= RandomForestClassifier()\n",
    "clf3.fit(X_train_encoded, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n",
      "[0 0 1 ... 1 0 1]\n",
      "Accuracy of training data: 0.9999385768250361\n",
      "Accuracy of test data: 0.8506234260794792\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "dot_data=StringIO()\n",
    "tree.export_graphviz(clf2,out_file=dot_data,filled=True,rounded=False,impurity=False)\n",
    "graph=pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png)\n",
    "\n",
    "predict1=clf3.predict(X_train_encoded)\n",
    "print(predict1)\n",
    "predict2=clf3.predict(X_test_encoded)\n",
    "print(predict2)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "c1=confusion_matrix(Ytrain,predict1)\n",
    "c1\n",
    "\n",
    "total=sum(sum(c1))\n",
    "#accuracy=(c1[0,0]+c1[1,1])/total\n",
    "a1=c1[0,0]\n",
    "a2=c1[1,1]\n",
    "accuracy=(a1+a2)/total\n",
    "print('Accuracy of training data:',accuracy)\n",
    "\n",
    "c2=confusion_matrix(Ytest,predict2)\n",
    "c2\n",
    "total1=sum(sum(c2))\n",
    "a3=c2[0,0]\n",
    "a4=c2[1,1]\n",
    "accuracy1=(a3+a4)/total1\n",
    "print('Accuracy of test data:',accuracy1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the defualt hyperparameter n_estimators parameter the accuracy of test data increases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try using different n_estimators values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf4= RandomForestClassifier(n_estimators=100,n_jobs = -1)\n",
    "clf4.fit(X_train_encoded, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n",
      "[0 0 0 ... 1 0 1]\n",
      "Accuracy of training data: 0.9999692884125181\n",
      "Accuracy of test data: 0.8516061666973773\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "dot_data=StringIO()\n",
    "tree.export_graphviz(clf2,out_file=dot_data,filled=True,rounded=False,impurity=False)\n",
    "graph=pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png)\n",
    "\n",
    "predict1=clf4.predict(X_train_encoded)\n",
    "print(predict1)\n",
    "predict2=clf4.predict(X_test_encoded)\n",
    "print(predict2)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "c1=confusion_matrix(Ytrain,predict1)\n",
    "c1\n",
    "\n",
    "total=sum(sum(c1))\n",
    "#accuracy=(c1[0,0]+c1[1,1])/total\n",
    "a1=c1[0,0]\n",
    "a2=c1[1,1]\n",
    "accuracy=(a1+a2)/total\n",
    "print('Accuracy of training data:',accuracy)\n",
    "\n",
    "c2=confusion_matrix(Ytest,predict2)\n",
    "c2\n",
    "total1=sum(sum(c2))\n",
    "a3=c2[0,0]\n",
    "a4=c2[1,1]\n",
    "accuracy1=(a3+a4)/total1\n",
    "print('Accuracy of test data:',accuracy1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the difference between the curve for a decision tree and for a random forest with an ensemble size of 1, and why do we see this difference?\n",
    "Random forest is more use full in feature predition than decision tree.\n",
    "What happens with the curve for random forests as the ensemble size grows?\n",
    "The accuracy of both the trian set and test set increases accordingly.\n",
    "What happens with the best observed test set accuracy as the ensemble size grows?\n",
    "We tried with two sample so, but we observed that when the the ensemble size increases the accuracy of both the trianing and test set increases.\n",
    "What happens with the training time as the ensemble size grows? \n",
    "Its accuracy approaches to 1. Therefore the model is good for both data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Feature importances in random forest classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Training Score: 1.00 \n",
      "OOB Score: 0.85 \n",
      "R^2 Validation Score: 0.85\n",
      "Accuracy: 0.8092868988391376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "rf = RandomForestClassifier(n_estimators = 100,\n",
    "                           n_jobs = -1,\n",
    "                           oob_score = True,\n",
    "                           bootstrap = True,\n",
    "                           random_state = 42)\n",
    "rf.fit(X_train_encoded, Ytrain)\n",
    "print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(rf.score(X_train_encoded, Ytrain), \n",
    "                                                                                            rf.oob_score_,\n",
    "                                                                                          rf.score(X_test_encoded, Ytest)))\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_new, Ytest))\n",
    "\n",
    "#import pandas as pd\n",
    "#clf1.fit(Xtrain,Ytrain)\n",
    "#feature_imp = pd.Series(clf1.feature_importances_,index=data_training.feature_names).sort_values(ascending=False)\n",
    "#feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this taks we calculated the importance scores for individual features and acucracy metric score for the predicted data and the test data from the previous steps "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
